const TOGGLE_BTN = document.getElementById("toggleBtn")
const USER_VISUALIZER = document.getElementById("userVisualizer")
const CHAT_HISTORY = document.getElementById("chatHistory")

const VOICE = window.speechSynthesis

let isChatting = false;
let speechObj = null;
let context = new AudioContext();
let stream = null
let animationId = null
let currentlySpeaking = null

const chatHistory = [{
  role: "system",
  content: "You are conversational and give short responses of no more than 2 sentences, no matter how complex the question. If you get a complex topic, you will engage in conversation rather than give a long response"
}]

const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition // SpeechRecognition | undefined

async function startChat() {
  TOGGLE_BTN.innerText = "Stop"
  speechObj = new SpeechRecognition()
  letUserSpeak()
}

function stopChat() {
  if (currentlySpeaking === "user") stopUserRecording()
  if (VOICE.speaking) VOICE.cancel()
  currentlySpeaking = null
  speechObj = null
  TOGGLE_BTN.innerText = "Start"
}

function appendContent({ role, content }) {
  chatHistory.push({ role, content })
  const contentEl = document.createElement('p')
  contentEl.innerText = content;
  contentEl.classList.add('speechBubble', role)
  CHAT_HISTORY.append(contentEl)
}

async function letUserSpeak() {
  currentlySpeaking = "user"
  const newStream = await navigator.mediaDevices.getUserMedia({
    audio: true,
  })
  stream = newStream
  const source = context.createMediaStreamSource(newStream)
  const analyzer = context.createAnalyser()
  source.connect(analyzer)
  animationId = updateUserBubble(analyzer)
  
  speechObj.start()
  speechObj.onresult = function transcribe(e) { // e: SpeechRecognitionEvent
    const { transcript } = e.results[0][0] // string
    appendContent({ role: currentlySpeaking, content: transcript })
    stopUserRecording()
    letAISpeak()
  }
}

async function letAISpeak() {
  currentlySpeaking = "assistant"
  const response = await (await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    body: JSON.stringify({
      model: "gpt-3.5-turbo",
      messages: chatHistory
    }),
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${OPENAI_API_KEY}`
    }
  })).json()
  const { content } = response.choices[0].message
  appendContent({ role: currentlySpeaking, content })

  const spokenResponse = new SpeechSynthesisUtterance(content)
  spokenResponse.onend = () => letUserSpeak()
  VOICE.speak(spokenResponse)
}

function updateUserBubble(analyzer) {
  const fbcArray = new Uint8Array(analyzer.frequencyBinCount)
  analyzer.getByteFrequencyData(fbcArray)
  const level = fbcArray.reduce((accum, val) => accum + val, 0) / fbcArray.length

  USER_VISUALIZER.style.transform = `scale(${level / 10})`
  
  animationId = requestAnimationFrame(() => updateUserBubble(analyzer))
}

function stopUserRecording() {
  cancelAnimationFrame(animationId)
  animationId = null
  stream.getTracks().forEach(s => s.stop())
  stream = null
  USER_VISUALIZER.style.transform = 'scale(0)'
}

TOGGLE_BTN.addEventListener("click", () => {
  isChatting = !isChatting;
  if (isChatting) {
    startChat();
  } else {
    stopChat();
  }
})